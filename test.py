import torch
import torch.nn as nn
from data.audio_dataloader import AudioDataloader
import os
from tqdm import tqdm

from data.preprocess import FeatureTypes

# === å‚æ•°é…ç½® ===
EPOCHS = 20
BATCH_SIZE = 16
LR = 1e-3
HIDDEN_SIZE = 128
NUM_LAYERS = 2
NUM_CLASSES = 25  # 12maj + 12min + N
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === æ¨¡åž‹å®šä¹‰ ===
class BiLSTMChordRecognizer(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_size=input_dim,
                            hidden_size=hidden_dim,
                            num_layers=num_layers,
                            batch_first=True,
                            dropout=0.3,
                            bidirectional=True)
        self.classifier = nn.Linear(hidden_dim * 2, num_classes)

    def forward(self, x):
        out, _ = self.lstm(x)  # out: (B, T, 2H)
        logits = self.classifier(out)  # (B, T, C)
        return logits


# === å‡†ç¡®çŽ‡è®¡ç®—å‡½æ•° ===
def accuracy(logits, labels):
    preds = torch.argmax(logits, dim=-1)
    mask = (labels != -100)
    correct = (preds == labels) & mask
    return correct.sum().item() / mask.sum().item()


# === ä¸»è®­ç»ƒå‡½æ•° ===
def train():
    # æ¨¡æ‹Ÿ configï¼ˆéœ€ä¸Žä½  preprocess ä½¿ç”¨çš„ä¸€è‡´ï¼‰
    config = {
        "mp3": {
            "song_hz": 22050,
            "inst_len": 10.0,
            "skip_interval": 5.0
        },
        "feature": {
            "n_bins": 168,
            "bins_per_octave": 24,
            "hop_length": 512
        }
    }

    # === æ•°æ®åŠ è½½å™¨ ===
    dataloader = AudioDataloader(
        config=config,
        data_root_dir="./data/Test_full/pt",  # æ‰€æœ‰ .pt æ•°æ®
        batch_size=BATCH_SIZE,
        val_split=0.15,
        shuffle=True,
        augment=False,
        featuretype=FeatureTypes.cqt,

    )
    train_loader, val_loader, test_loader = dataloader.get_loaders()

    # === åˆå§‹åŒ–æ¨¡åž‹ ===
    model = BiLSTMChordRecognizer(input_dim=168,
                                   hidden_dim=HIDDEN_SIZE,
                                   num_classes=NUM_CLASSES,
                                   num_layers=NUM_LAYERS).to(DEVICE)

    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    criterion = nn.CrossEntropyLoss(ignore_index=-100)  # å¿½ç•¥ padding ä½

    best_val_acc = 0.0

    for epoch in range(1, EPOCHS + 1):
        model.train()
        total_loss = 0
        total_acc = 0
        total_steps = 0

        print(f"\n[Epoch {epoch}] Training...")
        for X, y in tqdm(train_loader, desc=f"Train Epoch {epoch}"):
            X = X.to(DEVICE)      # (B, T, F)
            y = y.to(DEVICE)      # (B, T)

            logits = model(X)     # (B, T, C)
            loss = criterion(logits.view(-1, NUM_CLASSES), y.view(-1))
            acc = accuracy(logits, y)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            total_acc += acc
            total_steps += 1

        avg_loss = total_loss / total_steps
        avg_acc = total_acc / total_steps
        print(f"[Epoch {epoch}] Train Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}")

        # === éªŒè¯ ===
        model.eval()
        with torch.no_grad():
            val_loss = 0
            val_acc = 0
            steps = 0
            print(f"[Epoch {epoch}] Validating...")
            for X, y in tqdm(val_loader, desc=f"Val Epoch {epoch}"):
                X, y = X.to(DEVICE), y.to(DEVICE)
                logits = model(X)
                loss = criterion(logits.view(-1, NUM_CLASSES), y.view(-1))
                acc = accuracy(logits, y)
                val_loss += loss.item()
                val_acc += acc
                steps += 1
            val_loss /= steps
            val_acc /= steps

            print(f"           Val  Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

            # === æ¨¡åž‹ä¿å­˜ ===
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                torch.save(model.state_dict(), "best_bilstm_model.pt")
                print(f"           âœ… Saved best model (acc={val_acc:.4f})")

    print("\nâœ… Training complete!")

    # === æ¸¬è©¦ ===
    print("\n[Testing best model on test set...]")
    model.load_state_dict(torch.load("best_bilstm_model.pt"))
    model.eval()
    with torch.no_grad():
        test_loss = 0
        test_acc = 0
        test_steps = 0
        for X, y in tqdm(test_loader, desc="Testing"):
            X, y = X.to(DEVICE), y.to(DEVICE)
            logits = model(X)
            loss = criterion(logits.view(-1, NUM_CLASSES), y.view(-1))
            acc = accuracy(logits, y)
            test_loss += loss.item()
            test_acc += acc
            test_steps += 1
        test_loss /= test_steps
        test_acc /= test_steps
        print(f"\nðŸ“Š Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}")


if __name__ == "__main__":
    train()
